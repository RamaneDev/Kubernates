Best practice to develop app for K8S:
- thinking about pod's lifecycle
  - we have to make choise between the stateless or statefull pod's 
    depending of application to deploy (in case of rescheduling pod's data will be lost !)
  - in case of a multi-containers pod, if one container crash, the pod is still running 
    and it will keep running while one container run inside it, so a Replica-controller will 
    not reschedule the pod so we have to think about this situation before depoying

- deploying pods in order:
  - sometimes we want to delay the pod's starting for some sychronisations issues 
    (waiting for some services to be ready for exemple) we can use a initContainer 
    to prevent the main container form running, once the initContainer terminate, the 
    main container will be able to run. we can do this by setting initContainer 
    in pod manifest. this method can be used to manage the order of deploying of the pods

- BEST PRACTICES FOR HANDLING INTER-POD DEPENDENCIES :
  - The application needs to handle internally the possibility that its dependencies
    aren’t ready. And don’t forget readiness probes. If an app can’t do its job because one
    of its dependencies is missing, it should signal that through its readiness probe, so
    Kubernetes knows it, too, isn’t ready. You’ll want to do this not only because it prevents the app from being added as a service endpoint, but also because the app’s readiness is also used by the Deployment controller when performing a rolling update,
    thereby preventing a rollout of a bad version.

- Adding lifecycle hooks :
    We’ve talked about how init containers can be used to hook into the startup of the
    pod, but pods also allow you to define two lifecycle hooks:
        - Post-start hooks
        - Pre-stop hooks
    These lifecycle hooks are specified per container, unlike init containers, which apply
    to the whole pod. As their names suggest, they’re executed when the container starts
    and before it stops. 

- Understanding pod shutdown:
    We’ve touched on the subject of pod termination, so let’s explore this subject in more
    detail and go over exactly what happens during pod shutdown. This is important for
    understanding how to cleanly shut down an application running in a pod.

    Let’s start at the beginning. A pod’s shut-down is triggered by the deletion of the
    Pod object through the API server. Upon receiving an HTTP DELETE request, the
    API server doesn’t delete the object yet, but only sets a deletionTimestamp field in it.
    Pods that have the deletionTimestamp field set are terminating.

    Once the Kubelet notices the pod needs to be terminated, it starts terminating
    each of the pod’s containers. It gives each container time to shut down gracefully, but
    the time is limited. That time is called the termination grace period and is configurable per pod. 
    The timer starts as soon as the termination process starts. 
    Then the following sequence of events is performed:
        1 Run the pre-stop hook, if one is configured, and wait for it to finish.
        2 Send the SIGTERM signal to the main process of the container.
        3 Wait until the container shuts down cleanly or until the termination grace period runs out.
        4 Forcibly kill the process with SIGKILL, if it hasn’t terminated gracefully yet.


                                              Termination grace period
                                                          |
                                  ________________________|____________________________
                                 |                                                     |
                                                       SIGTERM                     SIGKILL   
                                                          |                           |
                                                          |                           |
                                                          |                           |
                                 |PRE-STOP HOOK PROCESS| \|/                         \|/
                                 |
    |||MAIN CONTAINER PROCESS -->|||||||||||MAIN CONTAINER PROCESS -->|||||||||||||||||
                                 |
                                \|/

                        Container shutdown
                            initiated

- IMPLEMENTING THE PROPER SHUTDOWN HANDLER IN YOUR APPLICATION :
   -  Applications should react to a SIGTERM signal by starting their shut-down procedure
      and terminating when it finishes. Instead of handling the SIGTERM signal, the application can be notified to shut down through a pre-stop hook. In both cases, the app
      then only has a fixed amount of time to terminate cleanly.

   -  if we can’t predict how long the app will take to shut down cleanly (in case of migration
       data ) 
        One solution is for the app (upon receipt of a termination signal) to create a new
        Job resource that would run a new pod, whose sole job is to migrate the deleted pod’s
        data to the remaining pods. But if you’ve been paying attention, you’ll know that you
        have no guarantee the app will indeed manage to create the Job object every single
        time. What if the node fails exactly when the app tries to do that?
        
        The proper way to handle this problem is by having a dedicated, constantly running pod that keeps checking for the existence of orphaned data. When this pod finds
        the orphaned data, it can migrate it to the remaining pods. Rather than a constantly
        running pod, you can also use a CronJob resource and run the pod periodically.
        
        You may think StatefulSets could help here, but they don’t. As you’ll remember,
        scaling down a StatefulSet leaves PersistentVolumeClaims orphaned, leaving the data
        stored on the PersistentVolume stranded. Yes, upon a subsequent scale-up, the PersistentVolume will be reattached to the new pod instance, but what if that scale-up never
        happens (or happens after a long time)? For this reason, you may want to run a
        data-migrating pod also when using StatefulSets (this scenario is shown in figure 17.6).
        To prevent the migration from occurring during an application upgrade, the datamigrating pod could be configured to wait a while to give the stateful pod time to
        come up again before performing the migration.

- Ensuring all client requests are handled properly :
  - when a pod is starting up : 
     -> by using the readiness (pods not ready will not be part of endpoints service 
        only a ready pod can be in endpoints list of service ).
  
  - when a pod shut-down :
     -> UNDERSTANDING THE SEQUENCE OF EVENTS OCCURRING AT POD DELETION (see Docs.docx).
     -> adding a readiness probe to your pod may solve the problem
