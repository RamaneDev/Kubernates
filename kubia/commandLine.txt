Best practice to develop app for K8S:
- thinking about pod's lifecycle
  - we have to make choise between the stateless or statefull pod's 
    depending of application to deploy (in case of rescheduling pod's data will be lost !)
  - in case of a multi-containers pod, if one container crash, the pod is still running 
    and it will keep running while one container run inside it, so a Replica-controller will 
    not reschedule the pod so we have to think about this situation before depoying

- deploying pods in order:
  - sometimes we want to delay the pod's starting for some sychronisations issues 
    (waiting for some services to be ready for exemple) we can use a initContainer 
    to prevent the main container form running, once the initContainer terminate, the 
    main container will be able to run. we can do this by setting initContainer 
    in pod manifest. this method can be used to manage the order of deploying of the pods

- BEST PRACTICES FOR HANDLING INTER-POD DEPENDENCIES :
  - The application needs to handle internally the possibility that its dependencies
    aren’t ready. And don’t forget readiness probes. If an app can’t do its job because one
    of its dependencies is missing, it should signal that through its readiness probe, so
    Kubernetes knows it, too, isn’t ready. You’ll want to do this not only because it prevents the app from being added as a service endpoint, but also because the app’s readiness is also used by the Deployment controller when performing a rolling update,
    thereby preventing a rollout of a bad version.

- Adding lifecycle hooks :
    We’ve talked about how init containers can be used to hook into the startup of the
    pod, but pods also allow you to define two lifecycle hooks:
        - Post-start hooks
        - Pre-stop hooks
    These lifecycle hooks are specified per container, unlike init containers, which apply
    to the whole pod. As their names suggest, they’re executed when the container starts
    and before it stops. 

- Understanding pod shutdown:
    We’ve touched on the subject of pod termination, so let’s explore this subject in more
    detail and go over exactly what happens during pod shutdown. This is important for
    understanding how to cleanly shut down an application running in a pod.

    Let’s start at the beginning. A pod’s shut-down is triggered by the deletion of the
    Pod object through the API server. Upon receiving an HTTP DELETE request, the
    API server doesn’t delete the object yet, but only sets a deletionTimestamp field in it.
    Pods that have the deletionTimestamp field set are terminating.

    Once the Kubelet notices the pod needs to be terminated, it starts terminating
    each of the pod’s containers. It gives each container time to shut down gracefully, but
    the time is limited. That time is called the termination grace period and is configurable per pod. 
    The timer starts as soon as the termination process starts. 
    Then the following sequence of events is performed:
        1 Run the pre-stop hook, if one is configured, and wait for it to finish.
        2 Send the SIGTERM signal to the main process of the container.
        3 Wait until the container shuts down cleanly or until the termination grace period runs out.
        4 Forcibly kill the process with SIGKILL, if it hasn’t terminated gracefully yet.


                                              Termination grace period
                                                          |
                                  ________________________|____________________________
                                 |                                                     |
                                                       SIGTERM                     SIGKILL   
                                                          |                           |
                                                          |                           |
                                                          |                           |
                                 |PRE-STOP HOOK PROCESS| \|/                         \|/
                                 |
    |||MAIN CONTAINER PROCESS -->|||||||||||MAIN CONTAINER PROCESS -->|||||||||||||||||
                                 |
                                \|/

                        Container shutdown
                            initiated

- IMPLEMENTING THE PROPER SHUTDOWN HANDLER IN YOUR APPLICATION :
   -  Applications should react to a SIGTERM signal by starting their shut-down procedure
      and terminating when it finishes. Instead of handling the SIGTERM signal, the application can be notified to shut down through a pre-stop hook. In both cases, the app
      then only has a fixed amount of time to terminate cleanly.

   -  if we can’t predict how long the app will take to shut down cleanly (in case of migration
       data ) 
        One solution is for the app (upon receipt of a termination signal) to create a new
        Job resource that would run a new pod, whose sole job is to migrate the deleted pod’s
        data to the remaining pods. But if you’ve been paying attention, you’ll know that you
        have no guarantee the app will indeed manage to create the Job object every single
        time. What if the node fails exactly when the app tries to do that?
        
        The proper way to handle this problem is by having a dedicated, constantly running pod that keeps checking for the existence of orphaned data. When this pod finds
        the orphaned data, it can migrate it to the remaining pods. Rather than a constantly
        running pod, you can also use a CronJob resource and run the pod periodically.
        
        You may think StatefulSets could help here, but they don’t. As you’ll remember,
        scaling down a StatefulSet leaves PersistentVolumeClaims orphaned, leaving the data
        stored on the PersistentVolume stranded. Yes, upon a subsequent scale-up, the PersistentVolume will be reattached to the new pod instance, but what if that scale-up never
        happens (or happens after a long time)? For this reason, you may want to run a
        data-migrating pod also when using StatefulSets (this scenario is shown in figure 17.6).
        To prevent the migration from occurring during an application upgrade, the datamigrating pod could be configured to wait a while to give the stateful pod time to
        come up again before performing the migration.

- Ensuring all client requests are handled properly :
  - when a pod is starting up : 
     -> by using the readiness (pods not ready will not be part of endpoints service 
        only a ready pod can be in endpoints list of service ).
  
  - when a pod shut-down :
     -> UNDERSTANDING THE SEQUENCE OF EVENTS OCCURRING AT POD DELETION (see Docs.docx).
     -> adding a readiness probe to your pod may solve the problem

- Properly tagging your images and using imagePullPolicy wisely:
        You’ll also soon learn that referring to the latest image tag in your pod manifests will
    cause problems, because you can’t tell which version of the image each individual pod
    replica is running. Even if initially all your pod replicas run the same image version, if
    you push a new version of the image under the latest tag, and then pods are rescheduled 
    (or you scale up your Deployment), the new pods will run the new version,
    whereas the old ones will still be running the old one. Also, using the latest tag
    makes it impossible to roll back to a previous version (unless you push the old version
    of the image again).

        It’s almost mandatory to use tags containing a proper version designator instead
    of latest, except maybe in development. Keep in mind that if you use mutable tags
    (you push changes to the same tag), you’ll need to set the imagePullPolicy field in
    the pod spec to Always. But if you use that in production pods, be aware of the big
    caveat associated with it. If the image pull policy is set to Always, the container 
    runtime will contact the image registry every time a new pod is deployed. This slows
    down pod startup a bit, because the node needs to check if the image has been modified. 
    Worse yet, this policy prevents the pod from starting up when the registry cannot be contacted.

- Using multi-dimensional instead of single-dimensional labels:
    Don’t forget to label all your resources, not only Pods. Make sure you add multiple
    labels to each resource, so they can be selected across each individual dimension. You
    (or the ops team) will be grateful you did it when the number of resources increases.
    Labels may include things like
        - The name of the application (or perhaps microservice) the resource belongs to
        - Application tier (front-end, back-end, and so on)
        - Environment (development, QA, staging, production, and so on)
        - Version
        - Type of release (stable, canary, green or blue for green/blue deployments, and
           so on)
        - Tenant (if you’re running separate pods for each tenant instead of using namespaces)
        - Shard for sharded systems
    This will allow you to manage resources in groups instead of individually and make it
    easy to see where each resource belongs

- Describing each resource through annotations
        To add additional information to your resources use annotations. At the least,
    resources should contain an annotation describing the resource and an annotation
    with contact information of the person responsible for it.
    In a microservices architecture, pods could contain an annotation that lists the
    names of the other services the pod is using. This makes it possible to show dependencies between pods. Other annotations could include build and version information
    and metadata used by tooling or graphical user interfaces (icon names, and so on).
    Both labels and annotations make managing running applications much easier, but
    nothing is worse than when an application starts crashing and you don’t know why.

- Providing information on why the process terminated (to explore in Kubernetes in action book)
- Handling application logs (to explore in Kubernetes in action book)
- Best practices for development and testing (to explore in Kubernetes in action book)
- Using Minikube in development (to explore in Kubernetes in action book)
- Versioning and auto-deploying resource manifests (to explore in Kubernetes in action book)
- Ksonnet as an alternative to writing YAML/JSON manifests (to explore in Kubernetes in action book)
- Employing Continuous Integration and Continuous Delivery (CI/CD) (to explore in generale)
  